{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2ed49d9",
   "metadata": {},
   "source": [
    "## FinTech Vendor Scorecard for Micro-Lending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7751815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from google.colab import files\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "data_path = \"./data/preprocessed_data.csv\"\n",
    "model_path = \"./amharic-ner-model\"\n",
    "output_report = \"./vendor_scorecard.md\"\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "# Load NER model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "id2label = model.config.id2label\n",
    "label2id = model.config.label2id\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Initialize NER pipeline\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "# Check for data file and handle upload\n",
    "if not os.path.exists(data_path):\n",
    "    print(\"Please upload preprocessed_data.csv\")\n",
    "    uploaded = files.upload()\n",
    "    uploaded_file = list(uploaded.keys())[0] if uploaded else None\n",
    "    if uploaded_file and os.path.exists(uploaded_file):\n",
    "        # Move uploaded file to ./data/\n",
    "        shutil.move(uploaded_file, data_path)\n",
    "    else:\n",
    "        raise FileNotFoundError(\"preprocessed_data.csv not found or upload failed.\")\n",
    "\n",
    "# Load preprocessed data\n",
    "df = pd.read_csv(data_path)\n",
    "# Rename 'text' to 'message' for consistency\n",
    "df = df.rename(columns={'text': 'message'})\n",
    "\n",
    "# Fallback regex for price extraction\n",
    "def fallback_price_extraction(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    matches = re.findall(r'(\\d+\\.?\\d*)\\s*ብር', text)\n",
    "    return [float(m) for m in matches]\n",
    "\n",
    "# Function to extract entities from text\n",
    "def extract_entities(text):\n",
    "    if not isinstance(text, str):\n",
    "        return [], []\n",
    "    predictions = ner_pipeline(text)\n",
    "    products, prices = [], []\n",
    "    current_product = []\n",
    "    current_price = []\n",
    "    for pred in predictions:\n",
    "        entity = pred[\"entity\"]\n",
    "        word = pred[\"word\"]\n",
    "        if entity.startswith(\"B-Product\"):\n",
    "            if current_product:\n",
    "                products.append(\" \".join(current_product))\n",
    "                current_product = []\n",
    "            current_product.append(word)\n",
    "        elif entity.startswith(\"I-Product\"):\n",
    "            current_product.append(word)\n",
    "        elif entity.startswith(\"B-PRICE\"):\n",
    "            if current_price:\n",
    "                prices.append(\" \".join(current_price))\n",
    "                current_price = []\n",
    "            current_price.append(word)\n",
    "        elif entity.startswith(\"I-PRICE\"):\n",
    "            current_price.append(word)\n",
    "    if current_product:\n",
    "        products.append(\" \".join(current_product))\n",
    "    if current_price:\n",
    "        prices.append(\" \".join(current_price))\n",
    "    # Use regex fallback if NER fails to extract prices\n",
    "    if not prices:\n",
    "        prices = [str(p) + \" ብር\" for p in fallback_price_extraction(text)]\n",
    "    return products, prices\n",
    "\n",
    "# Function to parse price to float (in Birr)\n",
    "def parse_price(price_str):\n",
    "    try:\n",
    "        match = re.search(r'(\\d+\\.?\\d*)\\s*ብር', price_str)\n",
    "        if match:\n",
    "            return float(match.group(1))\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Process vendor data\n",
    "def analyze_vendor(channel, vendor_df):\n",
    "    # Convert timestamps to datetime\n",
    "    vendor_df['timestamp'] = pd.to_datetime(vendor_df['timestamp'], errors='coerce')\n",
    "    vendor_df = vendor_df.dropna(subset=['timestamp'])\n",
    "\n",
    "    # Posting Frequency (posts per week)\n",
    "    min_date = vendor_df['timestamp'].min()\n",
    "    max_date = vendor_df['timestamp'].max()\n",
    "    days_diff = (max_date - min_date).days + 1\n",
    "    weeks = days_diff / 7 if days_diff > 0 else 1\n",
    "    posting_freq = len(vendor_df) / weeks\n",
    "\n",
    "    # Average Views per Post (not available)\n",
    "    avg_views = 0  # Placeholder due to missing 'views' column\n",
    "\n",
    "    # Top Performing Post (not available, select most recent post)\n",
    "    if not vendor_df.empty:\n",
    "        top_post = vendor_df.sort_values('timestamp', ascending=False).iloc[0]\n",
    "        top_views = 0  # Placeholder\n",
    "        top_message = top_post['message']\n",
    "        top_products, top_prices = extract_entities(top_message)\n",
    "        top_product = top_products[0] if top_products else \"Unknown\"\n",
    "        top_price = parse_price(top_prices[0]) if top_prices else None\n",
    "    else:\n",
    "        top_views, top_product, top_price, top_message = 0, \"None\", None, \"None\"\n",
    "\n",
    "    # Average Price Point\n",
    "    all_prices = []\n",
    "    for message in vendor_df['message']:\n",
    "        _, prices = extract_entities(message)\n",
    "        for price in prices:\n",
    "            parsed = parse_price(price)\n",
    "            if parsed:\n",
    "                all_prices.append(parsed)\n",
    "    avg_price = np.mean(all_prices) if all_prices else 0\n",
    "\n",
    "    # Lending Score (adjusted weights: 60% freq, 40% price due to missing views)\n",
    "    max_freq = 10      # Assumed max posts/week\n",
    "    max_price = 5000   # Assumed max price in Birr\n",
    "    norm_freq = min(posting_freq / max_freq, 1) if max_freq > 0 else 0\n",
    "    norm_price = min(avg_price / max_price, 1) if max_price > 0 else 0\n",
    "    lending_score = (0.6 * norm_freq + 0.4 * norm_price) * 100\n",
    "\n",
    "    return {\n",
    "        \"channel\": channel,\n",
    "        \"posting_frequency\": round(posting_freq, 2),\n",
    "        \"avg_views\": avg_views,\n",
    "        \"top_post\": {\n",
    "            \"views\": top_views,\n",
    "            \"product\": top_product,\n",
    "            \"price\": top_price,\n",
    "            \"message\": top_message\n",
    "        },\n",
    "        \"avg_price_point\": round(avg_price, 2),\n",
    "        \"lending_score\": round(lending_score, 2)\n",
    "    }\n",
    "\n",
    "# Analyze all vendors\n",
    "vendors = df['channel'].unique()\n",
    "results = []\n",
    "for channel in vendors:\n",
    "    vendor_df = df[df['channel'] == channel]\n",
    "    if not vendor_df.empty:\n",
    "        result = analyze_vendor(channel, vendor_df)\n",
    "        results.append(result)\n",
    "\n",
    "# Generate Scorecard Report\n",
    "report = \"# Vendor Scorecard for Micro-Lending\\n\\n\"\n",
    "report += \"## Overview\\n\"\n",
    "report += \"- **Objective**: Identify promising vendors for micro-lending based on activity and business profile.\\n\"\n",
    "report += \"- **Data Source**: Preprocessed Telegram posts (`preprocessed_data.csv`).\\n\"\n",
    "report += \"- **NER Model**: Fine-tuned `xlm-roberta-base` for entity extraction.\\n\\n\"\n",
    "\n",
    "report += \"## Vendor Metrics\\n\"\n",
    "for result in results:\n",
    "    report += f\"### Vendor: {result['channel']}\\n\"\n",
    "    report += f\"- **Posting Frequency**: {result['posting_frequency']} posts/week\\n\"\n",
    "    report += f\"- **Average Views per Post**: {result['avg_views']} views (not available in data)\\n\"\n",
    "    report += f\"- **Top Performing Post**:\\n\"\n",
    "    report += f\"  - Views: {result['top_post']['views']} (not available, showing most recent post)\\n\"\n",
    "    report += f\"  - Product: {result['top_post']['product']}\\n\"\n",
    "    report += f\"  - Price: {result['top_post']['price'] or 'Unknown'} Birr\\n\"\n",
    "    report += f\"  - Message: {result['top_post']['message'][:100] if isinstance(result['top_post']['message'], str) else 'None'}...\\n\"\n",
    "    report += f\"- **Average Price Point**: {result['avg_price_point']} Birr\\n\"\n",
    "    report += f\"- **Lending Score**: {result['lending_score']} (out of 100, adjusted for missing views)\\n\\n\"\n",
    "\n",
    "report += \"## Notes\\n\"\n",
    "report += \"- **Data Limitations**: Missing 'views' column prevents calculation of view-based metrics. Top post is the most recent post.\\n\"\n",
    "report += \"- **NER Limitations**: The NER model has low performance (0% F1 for Product, 3.01% F1 for LOC), affecting price and product extraction accuracy. Regex fallback used for prices.\\n\"\n",
    "report += \"- **Normalization**: Lending Score uses assumed max values (frequency: 10 posts/week, price: 5,000 Birr) with adjusted weights (60% frequency, 40% price).\\n\"\n",
    "report += \"- **Recommendations**: Re-scrape data to include view counts, improve NER model with more labeled data, validate timestamps, and collect engagement metrics (e.g., replies).\\n\"\n",
    "\n",
    "# Save report\n",
    "with open(output_report, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "# Download report\n",
    "files.download(output_report)\n",
    "\n",
    "print(\"Vendor analytics completed. Scorecard saved and downloaded as 'vendor_scorecard.md'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
