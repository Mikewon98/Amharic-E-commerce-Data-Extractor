{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8adbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()  # Upload conll_raw_sample.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d423457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conll(file_path):\n",
    "    sentences = []\n",
    "    tokens, labels = [], []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                if tokens:\n",
    "                    sentences.append((tokens, labels))\n",
    "                    tokens, labels = [], []\n",
    "            else:\n",
    "                splits = line.split()\n",
    "                if len(splits) >= 2:\n",
    "                    tokens.append(splits[0])\n",
    "                    labels.append(splits[1])\n",
    "    if tokens:\n",
    "        sentences.append((tokens, labels))\n",
    "    return sentences\n",
    "\n",
    "data = read_conll(\"data/conll_raw_sample.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c64146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "tokens = [x[0] for x in data]\n",
    "ner_tags = [x[1] for x in data]\n",
    "\n",
    "label_list = sorted(set(tag for seq in ner_tags for tag in seq))\n",
    "label2id = {l: i for i, l in enumerate(label_list)}\n",
    "id2label = {i: l for l, i in label2id.items()}\n",
    "\n",
    "tag_ids = [[label2id[tag] for tag in seq] for seq in ner_tags]\n",
    "\n",
    "dataset = Dataset.from_dict({\"tokens\": tokens, \"ner_tags\": tag_ids})\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45aa6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "model_name = \"FacebookAI/xlm-roberta-base\"  # Or use your preferred model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba49e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(example):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        example[\"tokens\"],\n",
    "        truncation=True,\n",
    "        padding='max_length',  # ✅ Add this\n",
    "        is_split_into_words=True,\n",
    "        max_length=128         # ✅ Optionally limit sequence length\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "    prev_word_id = None\n",
    "\n",
    "    for word_id in word_ids:\n",
    "        if word_id is None:\n",
    "            labels.append(-100)\n",
    "        elif word_id != prev_word_id:\n",
    "            labels.append(example[\"ner_tags\"][word_id] if word_id < len(example[\"ner_tags\"]) else -100)\n",
    "        else:\n",
    "            labels.append(example[\"ner_tags\"][word_id] if word_id < len(example[\"ner_tags\"]) else -100)\n",
    "        prev_word_id = word_id\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecc56f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fe250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./amharic-ner-results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd4977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_labels = [[id2label[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [id2label[pred] for pred, l in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return classification_report(true_labels, true_predictions, output_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e931f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeba3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate()\n",
    "print(\"Validation Results:\", results)\n",
    "\n",
    "# Save model and tokenizer locally\n",
    "model.save_pretrained(\"./amharic-ner-model\")\n",
    "tokenizer.save_pretrained(\"./amharic-ner-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f42f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import shap\n",
    "import lime\n",
    "import lime.lime_text\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from seqeval.metrics import classification_report\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "# Define paths\n",
    "model_path = \"./amharic-ner-model\"\n",
    "output_report = \"./amharic_ner_interpretability_report.md\"\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "id2label = model.config.id2label\n",
    "label2id = model.config.label2id\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Recreate test dataset\n",
    "def read_conll(file_path):\n",
    "    sentences = []\n",
    "    tokens, labels = [], []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                if tokens:\n",
    "                    sentences.append((tokens, labels))\n",
    "                    tokens, labels = [], []\n",
    "            else:\n",
    "                splits = line.split()\n",
    "                if len(splits) >= 2:\n",
    "                    tokens.append(splits[0])\n",
    "                    labels.append(splits[1])\n",
    "    if tokens:\n",
    "        sentences.append((tokens, labels))\n",
    "    return sentences\n",
    "\n",
    "# Check for data file\n",
    "if not os.path.exists(\"conll_raw_sample.txt\"):\n",
    "    print(\"Please upload conll_raw_sample.txt\")\n",
    "    uploaded = files.upload()\n",
    "    if not os.path.exists(\"conll_raw_sample.txt\"):\n",
    "        raise FileNotFoundError(\"conll_raw_sample.txt not found.\")\n",
    "\n",
    "data = read_conll(\"conll_raw_sample.txt\")\n",
    "tokens = [x[0] for x in data]\n",
    "ner_tags = [x[1] for x in data]\n",
    "label_list = sorted(set(tag for seq in ner_tags for tag in seq))  # Fixed NameError\n",
    "tag_ids = [[label2id[tag] for tag in seq] for seq in ner_tags]\n",
    "dataset = Dataset.from_dict({\"tokens\": tokens, \"ner_tags\": tag_ids})\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "# Tokenize test dataset\n",
    "def tokenize_and_align_labels(example):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        example[\"tokens\"],\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        is_split_into_words=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    labels = []\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "    prev_word_id = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id is None:\n",
    "            labels.append(-100)\n",
    "        elif word_id != prev_word_id:\n",
    "            labels.append(example[\"ner_tags\"][word_id] if word_id < len(example[\"ner_tags\"]) else -100)\n",
    "        else:\n",
    "            labels.append(example[\"ner_tags\"][word_id] if word_id < len(example[\"ner_tags\"]) else -100)\n",
    "        prev_word_id = word_id\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_and_align_labels, batched=False)\n",
    "\n",
    "# Initialize NER pipeline\n",
    "ner_pipeline = pipeline(\n",
    "    \"ner\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "# Function to prepare input for SHAP\n",
    "def predict_proba(texts):\n",
    "    # Handle 2D input by flattening if necessary\n",
    "    if isinstance(texts, np.ndarray) and texts.ndim > 1:\n",
    "        texts = texts.flatten()\n",
    "    inputs = tokenizer(texts.tolist() if isinstance(texts, np.ndarray) else texts,\n",
    "                      return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs).logits\n",
    "        probs = torch.softmax(outputs, dim=-1).cpu().numpy()\n",
    "    return probs.reshape(-1, len(id2label))\n",
    "\n",
    "# SHAP Explainer with corrected reference data\n",
    "reference_data = np.array([\"placeholder\"]).reshape(1, -1)  # Fixed for IndexError\n",
    "explainer_shap = shap.KernelExplainer(predict_proba, reference_data)\n",
    "\n",
    "# Function for LIME explanation\n",
    "def lime_predict_proba(texts):\n",
    "    return predict_proba(texts)\n",
    "\n",
    "# LIME Explainer\n",
    "lime_explanation = lime.lime_text.LimeTextExplainer(class_names=list(label2id.keys()), bow=False)\n",
    "\n",
    "# Analyze a sample from the test set\n",
    "sample = test_dataset[0]\n",
    "tokens = sample[\"tokens\"]\n",
    "true_labels = [id2label[l] for l in sample[\"ner_tags\"] if l != -100]\n",
    "text_input = \" \".join(tokens)\n",
    "\n",
    "# Get SHAP values\n",
    "try:\n",
    "    shap_values = explainer_shap.shap_values(text_input, nsamples=50)\n",
    "except Exception as e:\n",
    "    print(f\"SHAP error: {e}. Reducing nsamples or skipping SHAP.\")\n",
    "    shap_values = \"SHAP computation failed.\"\n",
    "\n",
    "# Get LIME explanation\n",
    "try:\n",
    "    lime_explanation = lime_explainer.explain_instance(text_input, lime_predict_proba, num_features=10, labels=range(len(id2label)))\n",
    "    lime_explanation_list = lime_explanation.as_list()\n",
    "except Exception as e:\n",
    "    print(f\"LIME error: {e}. Skipping LIME.\")\n",
    "    lime_explanation_list = \"LIME computation failed.\"\n",
    "\n",
    "# Predict with pipeline\n",
    "predictions = ner_pipeline(text_input)\n",
    "pred_labels = [pred[\"entity\"] for pred in predictions if \"entity\" in pred]\n",
    "\n",
    "# Analyze difficult cases\n",
    "difficult_cases = []\n",
    "for idx, example in enumerate(test_dataset):\n",
    "    tokens = example[\"tokens\"]\n",
    "    true_tags = [id2label[l] for l in example[\"ner_tags\"] if l != -100]\n",
    "    text = \" \".join(tokens)\n",
    "    preds = ner_pipeline(text)\n",
    "    pred_tags = [pred[\"entity\"] for pred in preds if \"entity\" in pred]\n",
    "    min_len = min(len(true_tags), len(pred_tags))\n",
    "    true_tags = true_tags[:min_len]\n",
    "    pred_tags = pred_tags[:min_len]\n",
    "    if min_len > 0:\n",
    "        incorrect = [t != p for t, p in zip(true_tags, pred_tags)]\n",
    "        if any(incorrect):\n",
    "            difficult_cases.append({\n",
    "                \"index\": idx,\n",
    "                \"tokens\": tokens,\n",
    "                \"true_labels\": true_tags,\n",
    "                \"pred_labels\": pred_tags,\n",
    "                \"incorrect_positions\": [i for i, x in enumerate(incorrect) if x]\n",
    "            })\n",
    "\n",
    "# Generate classification report\n",
    "true_all = []\n",
    "pred_all = []\n",
    "for example in test_dataset:\n",
    "    true_tags = [id2label[l] for l in example[\"ner_tags\"] if l != -100]\n",
    "    text = \" \".join(example[\"tokens\"])\n",
    "    preds = ner_pipeline(text)\n",
    "    pred_tags = [pred[\"entity\"] for pred in preds if \"entity\" in pred]\n",
    "    min_len = min(len(true_tags), len(pred_tags))\n",
    "    true_all.append(true_tags[:min_len])\n",
    "    pred_all.append(pred_tags[:min_len])\n",
    "report_dict = classification_report(true_all, pred_all, output_dict=True)\n",
    "\n",
    "# Generate Interpretability Report\n",
    "report = f\"\"\"\n",
    "# Amharic NER Model Interpretability Report\n",
    "\n",
    "## 1. Model Overview\n",
    "- **Model**: {model_path} (based on xlm-roberta-base)\n",
    "- **Task**: Named Entity Recognition (NER) for Amharic text\n",
    "- **Labels**: {list(id2label.values())}\n",
    "\n",
    "## 2. SHAP Analysis\n",
    "### Sample Text: {\" \".join(sample[\"tokens\"])}\n",
    "### SHAP Insights:\n",
    "- Top contributing tokens for each label:\n",
    "{shap_values}\n",
    "\n",
    "## 3. LIME Analysis\n",
    "### LIME Explanation for Sample:\n",
    "{lime_explanation_list}\n",
    "\n",
    "## 4. Performance Metrics\n",
    "### Classification Report:\n",
    "{pd.DataFrame(report_dict).T.to_markdown()}\n",
    "\n",
    "## 5. Difficult Cases Analysis\n",
    "### Number of Difficult Cases: {len(difficult_cases)}\n",
    "### Example Difficult Case:\n",
    "{difficult_cases[0] if difficult_cases else \"No difficult cases found.\"}\n",
    "\n",
    "## 6. Recommendations for Improvement\n",
    "- **Ambiguous Entities**: If 'LOC' performance is low, collect more diverse location data.\n",
    "- **Overlapping Entities**: Enhance tokenization to handle multi-word entities.\n",
    "- **Data Augmentation**: Use synthetic Amharic NER data to increase dataset size.\n",
    "- **Hyperparameter Tuning**: Try learning rates (e.g., 5e-5) or more epochs (e.g., 5).\n",
    "\"\"\"\n",
    "\n",
    "# Save report\n",
    "with open(output_report, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "# Download report\n",
    "files.download(output_report)\n",
    "\n",
    "print(\"Interpretability analysis completed. Report saved and downloaded as 'amharic_ner_interpretability_report.md'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
